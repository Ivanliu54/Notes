# Tasks of Machine Vision

## 一. 任务概述

### 1. Image Classification (分类)

关注图像整体（人脸识别）

### 2. Objdect detection （目标检测）

图片里有什么？分别在哪？

主要方法： Faster R-cnn / YOLO

### 3. Semantic segmentation（语义分割）

区分每一个像素属于哪一类，但是不区分同一类下的不同个体。

### 4. Instance segmentation (实例分割)

目标检测和语义分割的集合，相对于目标检测（画框），实例分割精度到物体边缘；相对于语义分割，实例分割需要比哦啊住处同一类物体的不同实例。

常用方法：Mask R-CNN

Mask R-CNN 通过向 Faster R-CNN 添加一个分支来进行像素级分割，该分支输出一个二进制掩码，该掩码表示给定像素是否为目标对象的一部分：该分支是基于卷积神经网络特征映射的全卷积网络。将给定的卷积神经网络特征映射作为输入，输出为一个矩阵，其中像素属于该对象的所有位置用 1 表示，其他位置则用 0 表示，这就是二进制掩码。

一旦生成这些掩码， Mask R-CNN 将 RoIAlign 与来自 Faster R-CNN 的分类和边界框相结合，以便进行精确的分割：

### 5. Panoramica Sementation (全景分割)

全景分割是语义分割和实例分割的结合。跟实例分割不同的是：实例分割只对图像中的object进行检测，并对检测到的object进行分割，而全景分割是对图中的所有物体包括背景都要进行检测和分割

![Alt pic](http://5b0988e595225.cdn.sohucs.com/images/20180124/f72034dd098144658a4a718ac8d0b451.jpeg "图片")


## 二. 数据库

### 1. Classification 

以下是几种常用分类数据集，难度依次递增。

MNIST 60k训练图像、10k测试图像、10个类别、图像大小1×28×28、内容是0-9手写数字。
CIFAR-10 50k训练图像、10k测试图像、10个类别、图像大小3×32×32。
CIFAR-100 50k训练图像、10k测试图像、100个类别、图像大小3×32×32。
ImageNet 1.2M训练图像、50k验证图像、1k个类别。2017年及之前，每年会举行基于ImageNet数据集的ILSVRC竞赛，这相当于计算机视觉界奥林匹克。

### 2. Object detection


PASCAL VOC 包含20个类别。通常是用VOC07和VOC12的trainval并集作为训练，用VOC07的测试集作为测试。
MS COCO COCO比VOC更困难。COCO包含80k训练图像、40k验证图像、和20k没有公开标记的测试图像(test-dev)，80个类别，平均每张图7.2个目标。通常是用80k训练和35k验证图像的并集作为训练，其余5k图像作为验证，20k测试图像用于线上测试。
mAP (mean average precision) 目标检测中的常用评价指标，计算方法如下。当预测的包围盒和真实包围盒的交并比大于某一阈值(通常为0.5)，则认为该预测正确。对每个类别，我们画出它的查准率-查全率(precision-recall)曲线，平均准确率是曲线下的面积。之后再对所有类别的平均准确率求平均，即可得到mAP，其取值为[0, 100%]。
交并比(intersection over union, IoU) 算法预测的包围盒和真实包围盒交集的面积除以这两个包围盒并集的面积，取值为[0, 1]。交并比度量了算法预测的包围盒和真实包围盒的接近程度，交并比越大，两个包围盒的重叠程度越高


## 三. 常用网络


***基本架构*** 我们用conv代表卷积层、bn代表批量归一层、pool代表汇合层。最常见的网络结构顺序是conv -> bn -> relu -> pool，其中卷积层用于提取特征、汇合层用于减少空间大小。随着网络深度的进行，图像的空间大小将越来越小，而通道数会越来越大。

***针对你的任务，如何设计网络？*** 当面对你的实际任务时，如果你的目标是解决该任务而不是发明新算法，那么不要试图自己设计全新的网络结构，也不要试图从零复现现有的网络结构。找已经公开的实现和预训练模型进行微调。去掉最后一个全连接层和对应softmax，加上对应你任务的全连接层和softmax，再固定住前面的层，只训练你加的部分。如果你的训练数据比较多，那么可以多微调几层，甚至微调所有层。


### 1. Classification

### 2. Object detection
基本思路

多任务学习，网络带有两个输出分支。一个分支用于做图像分类，即全连接+softmax判断目标类别，和单纯图像分类区别在于这里还另外需要一个“背景”类。另一个分支用于判断目标位置，即完成回归任务输出四个数字标记包围盒位置(例如中心点横纵坐标和包围盒长宽)，该分支输出结果只有在分类分支判断不为“背景”时才使用。










[各算法在各数据集上的性能排名。](http://rodrigob.github.io/are_we_there_yet/build/)